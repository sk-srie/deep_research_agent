"""
Embedding generation module for Deep Researcher Agent.

This module provides functionality to generate embeddings for documents and queries
using the sentence-transformers library for local embedding generation.
"""

from typing import List, Union
import numpy as np
from sentence_transformers import SentenceTransformer
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class EmbeddingGenerator:
    """
    A class to handle embedding generation using sentence-transformers.
    
    This class provides methods to generate embeddings for documents and queries
    using a pre-trained sentence transformer model.
    """
    
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        """
        Initialize the embedding generator with a sentence transformer model.
        
        Args:
            model_name (str): Name of the sentence transformer model to use.
                             Default is "all-MiniLM-L6-v2" which is fast and efficient.
        """
        self.model_name = model_name
        self.model = None
        self._load_model()
    
    def _load_model(self) -> None:
        """Load the sentence transformer model."""
        try:
            logger.info(f"Loading sentence transformer model: {self.model_name}")
            self.model = SentenceTransformer(self.model_name)
            logger.info("Model loaded successfully")
        except Exception as e:
            logger.error(f"Error loading model: {e}")
            raise
    
    def generate_embeddings(self, texts: Union[str, List[str]]) -> np.ndarray:
        """
        Generate embeddings for the given text(s).
        
        Args:
            texts (Union[str, List[str]]): Single text string or list of text strings
                                         to generate embeddings for.
        
        Returns:
            np.ndarray: Array of embeddings with shape (n_texts, embedding_dim)
        """
        if self.model is None:
            raise ValueError("Model not loaded. Please initialize the EmbeddingGenerator.")
        
        try:
            # Ensure texts is a list
            if isinstance(texts, str):
                texts = [texts]
            
            logger.info(f"Generating embeddings for {len(texts)} text(s)")
            embeddings = self.model.encode(texts, convert_to_numpy=True)
            logger.info(f"Generated embeddings with shape: {embeddings.shape}")
            
            return embeddings
        except Exception as e:
            logger.error(f"Error generating embeddings: {e}")
            raise
    
    def get_embedding_dimension(self) -> int:
        """
        Get the dimension of the embeddings generated by this model.
        
        Returns:
            int: The embedding dimension
        """
        if self.model is None:
            raise ValueError("Model not loaded. Please initialize the EmbeddingGenerator.")
        
        # Generate a dummy embedding to get the dimension
        dummy_embedding = self.generate_embeddings("dummy text")
        return dummy_embedding.shape[1]
    
    def get_model_info(self) -> dict:
        """
        Get information about the current model.
        
        Returns:
            dict: Dictionary containing model information
        """
        return {
            "model_name": self.model_name,
            "embedding_dimension": self.get_embedding_dimension(),
            "model_loaded": self.model is not None
        }


def generate_embeddings(texts: Union[str, List[str]], 
                       model_name: str = "all-MiniLM-L6-v2") -> np.ndarray:
    """
    Convenience function to generate embeddings for texts.
    
    Args:
        texts (Union[str, List[str]]): Single text string or list of text strings
                                     to generate embeddings for.
        model_name (str): Name of the sentence transformer model to use.
    
    Returns:
        np.ndarray: Array of embeddings with shape (n_texts, embedding_dim)
    """
    generator = EmbeddingGenerator(model_name)
    return generator.generate_embeddings(texts)


if __name__ == "__main__":
    # Test the embedding generation
    generator = EmbeddingGenerator()
    
    # Test with single text
    single_text = "This is a test document for embedding generation."
    single_embedding = generator.generate_embeddings(single_text)
    print(f"Single text embedding shape: {single_embedding.shape}")
    
    # Test with multiple texts
    multiple_texts = [
        "This is the first document.",
        "This is the second document.",
        "This is the third document."
    ]
    multiple_embeddings = generator.generate_embeddings(multiple_texts)
    print(f"Multiple texts embedding shape: {multiple_embeddings.shape}")
    
    # Print model info
    print(f"Model info: {generator.get_model_info()}")
